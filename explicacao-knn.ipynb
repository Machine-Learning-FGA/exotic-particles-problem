{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN _versus_ SGD \n",
    "\n",
    "A equipe segue recomendações presentes nas [documentações](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) do sklearn.\n",
    "\n",
    "O terceiro encontro da equipe reuniu esforços para estreitar os métodos de classificação a serem utilizados que trouxessem uma maior acurácia quanto aos resultados. Nesse sentido, primeiramente foi necessário analisar a base de dados, conhecendo a dimensão desta, de modo que observou-se um total de 5.000.000 de registros. Constatou-se que o problema apresentado girava em torno da tarefa de predizer uma categoria por meio de dados que apresentam labels, ou seja, um problema de classificação. \n",
    "\n",
    "Pela dimensão do banco optou-se testou-se _Support Vector Classification_ ou SVC, mas não obteve-se sucesso, além disso, não envolvia problemas relacionados a texto, por tanto, a equipe não testou Naive Bayes, partindo então para _Nearest Neighbors Classification_. A princípio mostrou resultados razoáveis, como é possível ver [aqui](#knnAcuracia), entretanto, o número de dados processados não englobava todos os registros do dataset. Por meio do [tutorial](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) do scikitlearn, percebeu-se que esse método não era recomendado para conjunto de dados maiores que 100k.\n",
    "\n",
    "A incompatibilidade relatada, pode ser observada devido ao fato de que com acréscimos no número de registros a serem processados o algorítmo se tornava demasiadamente lento, como pode-se testar e observar na seção [Tempo de Execução](#tempoExecucao).  A partir de então, a equipe optou por testar [SGDClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html).\n",
    "\n",
    "\n",
    "## Nearest Neighbors Classification\n",
    "\n",
    "A classificação baseada em vizinhos é um tipo de aprendizado que se baseia em intâncias : não tenta construir um modelo interno geral, mas simplesmente armazena instâncias dos dados de treinamento. A classificação é calculada a partir de uma votação simples dos vizinhos mais próximos de cada ponto.\n",
    "\n",
    "A classificação básica de vizinhos mais próximos usa pesos uniformes: o valor atribuído a um ponto é calculado a partir de uma votação simples por maioria  dos vizinhos mais próximos. Em algumas circunstâncias, é melhor ponderar os vizinhos de tal forma que os vizinhos mais próximos contribuam mais para o ajuste.\n",
    "\n",
    "[Documentação](http://scikit-learn.org/stable/modules/neighbors.html#classification)\n",
    "\n",
    "\n",
    "## KNeighborsClassifier\n",
    "\n",
    "É um algorítmo classificador que implementa o voto entre os k vizinhos mais próximos. \n",
    "\n",
    "[Documentação](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "## SGD - Stochastic Gradient Descent\n",
    "\n",
    "O Algorítmo SGD é uma abordagem simples porém eficiente, sendo esta abordagem, facilmente implementada. A abordagem SGD é utilizada para modelos discriminativos com classificadores lineares sobre funções convexas de perda, tais como a regressão linear.Bastante aplicado em aprendizado de larga escala, o SGDClassifier é a alternativa para bases de dados em que o KNeighborsClassifier se mostra ineficiente.\n",
    "\n",
    "Por trabalhar com bases de dados de grande volume, o SGD necessita de hiper parametros, ou seja, necessita que sejam analisadas as features mais relevantes. Isso se alcança com uma boa feature selection antes de se aplicar o SGD Classifier.\n",
    "\n",
    "[Documentação](http://scikit-learn.org/stable/modules/sgd.html)\n",
    "\n",
    "## SGDClassifier\n",
    "\n",
    "É um algorítmo classificador que implementa modelos lineares utilizando curvas de gradiente.\n",
    "\n",
    "[documentacao](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "\n",
    "## Importando os módulos necessários\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os dados do arquivo csv (apenas as 100000 observações finais do arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(9,10,11,12,13,14,15,16,17,18), skip_footer=4900000)\n",
    "v = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(0), skip_footer=4900000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seletor de features que remove todas as que possuem baixa variação\n",
    "\n",
    "[Documentação VarianceThreshold](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "dataset_susy = sel.fit_transform(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parcela de treino e de teste dos dados (30% teste, 70% treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_susy[0,:]\n",
    "\n",
    "t_treino, t_teste, v_treino, v_teste = train_test_split(dataset_susy, v, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testa o KNeighborsClassifier variando o número de vizinhos para comparar a acurácia \n",
    "<a name=\"knnAcuracia\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.7100666666666666\n",
      "2 : 0.7316333333333334\n",
      "3 : 0.7428333333333333\n",
      "4 : 0.7538666666666667\n",
      "5 : 0.7570666666666667\n",
      "6 : 0.7621666666666667\n",
      "7 : 0.7650666666666667\n",
      "8 : 0.7683666666666666\n",
      "9 : 0.7690666666666667\n",
      "10 : 0.7701\n",
      "11 : 0.7734333333333333\n",
      "12 : 0.7731\n",
      "13 : 0.7745\n",
      "14 : 0.7739333333333334\n",
      "15 : 0.7762\n",
      "16 : 0.7758333333333334\n",
      "17 : 0.7783333333333333\n",
      "18 : 0.7772333333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 19):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, p=2)\n",
    "    knn.fit(t_treino, v_treino)\n",
    "    labels = knn.predict(t_teste)\n",
    "    print(\"{} : {}\".format(i, knn.score(t_teste, v_teste)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marcando tempo de execução com diferentes tamanhos de dataset\n",
    "\n",
    "<a name=\"tempoExecucao\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando módulos necessários (SE não foi feito anteriormente)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar para 100.000 registros\n",
    "\n",
    "t = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(9,10,11,12,13,14,15,16,17,18), skip_footer=4900000)\n",
    "v = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(0), skip_footer=4900000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar para 200.000 registros\n",
    "\n",
    "t = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(9,10,11,12,13,14,15,16,17,18), skip_footer=4800000)\n",
    "v = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(0), skip_footer=4800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar para 500.000 registros\n",
    "\n",
    "t = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(9,10,11,12,13,14,15,16,17,18), skip_footer=4500000)\n",
    "v = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(0), skip_footer=4500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepara treino e Teste\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "dataset_susy = sel.fit_transform(t)\n",
    "dataset_susy[0,:]\n",
    "\n",
    "t_treino, t_teste, v_treino, v_teste = train_test_split(dataset_susy, v, test_size=0.3, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.7100666666666666, tempo de execução: 1.1225450038909912\n",
      "2 : 0.7316333333333334, tempo de execução: 1.3792622089385986\n",
      "3 : 0.7428333333333333, tempo de execução: 1.5731890201568604\n",
      "4 : 0.7538666666666667, tempo de execução: 1.76546311378479\n",
      "5 : 0.7570666666666667, tempo de execução: 1.9049127101898193\n",
      "6 : 0.7621666666666667, tempo de execução: 2.0000760555267334\n",
      "7 : 0.7650666666666667, tempo de execução: 2.1464481353759766\n",
      "8 : 0.7683666666666666, tempo de execução: 2.1939520835876465\n",
      "9 : 0.7690666666666667, tempo de execução: 2.291718006134033\n",
      "10 : 0.7701, tempo de execução: 2.409843921661377\n",
      "11 : 0.7734333333333333, tempo de execução: 2.4897096157073975\n",
      "12 : 0.7731, tempo de execução: 2.587857484817505\n",
      "13 : 0.7745, tempo de execução: 2.6491429805755615\n",
      "14 : 0.7739333333333334, tempo de execução: 2.7390315532684326\n",
      "15 : 0.7762, tempo de execução: 2.8591177463531494\n",
      "16 : 0.7758333333333334, tempo de execução: 2.9757251739501953\n",
      "17 : 0.7783333333333333, tempo de execução: 3.0982158184051514\n",
      "18 : 0.7772333333333333, tempo de execução: 2.935885429382324\n"
     ]
    }
   ],
   "source": [
    "# Tempo de execução (teste para i vizinhos)\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "for i in range(1, 19):\n",
    "    inicio = time.time()\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, p=2)\n",
    "    knn.fit(t_treino, v_treino)\n",
    "    labels = knn.predict(t_teste)\n",
    "    fim = time.time()\n",
    "    print(\"{} : {}, tempo de execução (em segundos): {}\".format(i, knn.score(t_teste, v_teste), (fim-inicio)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se a partir da célula anterior, que além de o tempo aumentar com o número de registros processados, também aumenta com o número de vizinhos a serem considerados nas interações.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
