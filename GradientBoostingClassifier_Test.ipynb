{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção de features do dataset SUSY\n",
    "\n",
    "O dataset possui 5 milhões de amostras de simulações. A classe é indicada na primeira coluna (0 ou 1); as 8 colunas seguintes são features obtidas originalmente das simulações, e as 10 seguintes são features computadas a partir das anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Gradient Tree Boosting\n",
    "\n",
    "O Gradient Boosting ou Gradient Boosted Regression Trees (GBRT) é uma generalização de estímulo/impulsionamento para funções de perda arbitrariamente diferenciáveis. O GBRT é um procedimento pronto e efetivo que pode ser usado tanto para problemas de regressão quanto de classificação. Modelos de Gradient Tree Boosting são usados ​​em uma variedade de áreas, incluindo ranking de busca na Web e ecologia.\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "\n",
    "É usado em problemas de classificação e suporta classificação binária e multi-classe. \n",
    "\n",
    "O número de apredizes fracos ou árvores de regressão pode ser controlado pelo parâmetro n_estimators, além disso, o tamanho de cada árvore é definido pela profundidade da árvore via max_depth definindo o número de nós de folha via max_leaf_nodes. O learning_rate é um hiper-parâmetro no intervalo (0.0, 1.0) que controla o overfitting através do encolhimento .\n",
    "\n",
    "[gradient-boosting](http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)\n",
    "\n",
    "# Testando GradientBoostingClassifier\n",
    "\n",
    "[documentação](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os módulos a serem utilizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dados do arquivo csv (apenas as 200000 observações finais do arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,17,18), skip_header=4400000)\n",
    "y = np.genfromtxt('SUSY.csv', delimiter=',', usecols=(0), skip_header=4400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os dados nos subconjuntos de treino e teste. Os dois subconjuntos terão tamanhos iguais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimindo o tamanho do subconjunto de treino (apenas um teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_treino))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializando o GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=900, min_samples_split=700, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o modelo/algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=700,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=900,\n",
       "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando a previsão das etiquetas das observações de acordo com o modelo/algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = gb.predict(x_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimindo a quantidade e as etiquetas previstas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo/algoritmo (faltando a coluna 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79737\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculando a acurácia do modelo/algoritmo (incluindo a coluna 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80047\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo/algoritmo (com dataset de treino de 70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo/algoritmo (com dataset de treino de 75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80134\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo/algoritmo (total de 400.000 observações com dataset de treino de 75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80062\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo/algoritmo (total de 600.000 observações com dataset de treino de 75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8025266666666667\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo/algoritmo (total de 200.000 observações com dataset de treino de 75% e min_samples_split=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80138\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a acurácia do modelo/algoritmo (total de 600.000 observações com dataset de treino de 75% e min_samples_split=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80254\n"
     ]
    }
   ],
   "source": [
    "print(gb.score(x_teste, y_teste))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
